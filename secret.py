import pdfplumber
import pandas as pd
import os
import re
import streamlit as st

def extract_all_data(pdf_path):
    """
    Extracts data from all pages of a PDF based on Pro_CC_ID logic.
    """
    all_extracted_data = []
    
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages, 1):
            page_text = page.extract_text(x_tolerance=2, y_tolerance=2)
            if not page_text:
                continue
            
            lines = page_text.split('\n')
            
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line:
                    continue
                
                parts = line.split()
                if not parts:
                    continue
                
                if parts[0] in ["R2", "R3"]:
                    continue

                result = ""
                unit = ""
                
                has_plus = line.startswith('+')
                
                if parts[0] == "ISE" or (has_plus and len(parts) > 1 and parts[1] == "ISE"):
                    if has_plus:
                        if len(parts) >= 4: result = parts[3]
                    else:
                        if len(parts) >= 3: result = parts[2]
                elif has_plus:
                    if len(parts) >= 3: result = parts[2]
                else:
                    if len(parts) >= 2:
                        try:
                            float(parts[1].replace(',', '.'))
                            result = parts[1]
                        except (ValueError, IndexError):
                            pass

                if result:
                    if line_num < len(lines):
                        next_line = lines[line_num].strip()
                        next_parts = next_line.split()
                        if next_parts and any(u in next_line for u in ['mg/dL', 'g/dL', 'mmol/L', 'U/L', '%', 'mEq/L']):
                            unit = next_parts[0]
                    
                    all_extracted_data.append({
                        "íŽ˜ì´ì§€": page_num,
                        "ì¤„": line_num,
                        "Result": result.replace(',', '.'),
                        "Unit": unit,
                    })

    return all_extracted_data

def run(pdf_path, excel_path_ignored):
    """
    Main function to be called from app.py.
    """
    st.info(f"ì¸„ë¦…ì„ ì‹œìž‘í•©ë‹ˆë‹¤... PDF íŒŒì¼: {os.path.basename(pdf_path)}")
    
    try:
        data_to_excel = extract_all_data(pdf_path)
        
        if not data_to_excel:
            st.warning("PDFì—ì„œ Result ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Pro_CC_ID í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”)")
            return

        df = pd.DataFrame(data_to_excel)
        df["ìˆ˜ì •í•  Result"] = ""
        df = df[["íŽ˜ì´ì§€", "ì¤„", "Result", "Unit", "ìˆ˜ì •í•  Result"]]
        
        output_dir = os.path.dirname(pdf_path)
        pdf_basename = os.path.splitext(os.path.basename(pdf_path))[0]
        output_excel_path = os.path.join(output_dir, f"SECRET_EXTRACT_{pdf_basename}.xlsx")
        
        df.to_excel(output_excel_path, index=False)
        
        st.success(f"ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ! ì•„ëž˜ëŠ” ì¶”ì¶œëœ ë°ì´í„°ìž…ë‹ˆë‹¤.")
        st.dataframe(df)
        
        with open(output_excel_path, "rb") as f:
            data = f.read()
        st.download_button(
            label="ðŸ“¥ ì¶”ì¶œëœ Excel ë‹¤ìš´ë¡œë“œ",
            data=data,
            file_name=os.path.basename(output_excel_path),
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except Exception as e:
        st.error(f"secret.py ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        st.code(traceback.format_exc())